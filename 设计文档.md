##### 数据处理流程设计文档

###### 系统目标
           设计这个系统的主要目标是用户只需要通过前端配置数据处理流程、后台就能完成用户定义的数据处理任务
       （Flink Job,MR Job）的自动装配和提交任务；在大部分情况下直接通过页面配置流程就能实现任务，提高程序的开发效率。
        
###### 设计要求
        1.能灵活的配置大部分数据流程
        2.可能需要完善的流程分析、这一点也是需要结合实际应用场景去积累通用的数据处理方式
        3.能将数据处理流程从数据处理框架中剥离出来，例如：可以用于Spark，Flink，Hadoop等都可以
        
        
###### 设计概要
       
          data-process-functional-service：主要是数据的转换操作，目前支持的是数据编码、解码、正则表达式、分割等功能、
          富化函数、规则引擎、外部系统数据关联等数据变换操作。
          设计方式：将这些一系列的数据变换操作抽象成Command对不同的Command可以进行不同方式的线性组合，
                    可以达到对数据不同处理流程的定义。通过构造不同的Command的方式向外提供可调用的API，
                    同时第三方可以按需求定义自己的Command满足业务要求。
        
          data-manage-service：这个组件主要是负责数据类型的定义（Schema的定义、字段的定义、存储策略等）和管理(数据类型的
         CURD、权限)、数据轨迹的管理（可以进行溯源）等方面的功能。定义好数据的管理程度决定着企业的数据和业务之间结合紧密
         度高低与否，所以良好的数据管理系统能促进企业的业务发展。
         设计功能规划：Schema的定义、字段的定义、存储策略等；数据类型的CURD、权限；数据轨迹的管理
           
           data-process-flow：这个组件是数据处理流程、是想描述一条数据或某个类型的数据经过哪些主要步骤的处理。
           它的设计主要是连接数据类型和数据处理作业之间的枢纽；
           它的设计要求比较高：1.需要考虑能扩展所有的不同作业方式的系统，例如：Spark、Flink、Hadoop等
                               2.目的就是通过对数据流程的定义，系统能自动生成该数据流程的作业任务。
                               最后的效果就是：用户在界面上定义好一套数据处理流程，选择Flink作业方式；
                               然后submit该Job到Flink集群上运行，用户就完成了作业的开发、运行。        
         
        关键点：
            1.是如何定义数据处理节点的模型、需要结合数据处理功能模块、作业系统的特点（Flink、Spark）等去普适这些框架
            2.数据流程需要将数据类型结合起来定义流程处理节点
            3.数据处理流程、子流程、之间的关系和作业运行怎么处理
        
        当前版本设计：只按Flink的数据处理框架去适配、上述的数据处理功能服务主要是针对数据的变换进行封装；但是实际数据处理中
        还会涉及到数据的查询、过滤、聚合（窗口计算）、流关联等操作；对这些操作的融合，可以更多的考虑FlinkSQL的方式进行集成。
        
        
        
##### 系统存在的缺点
       1.因为数据转换不可能覆盖所有的具体场景、所以支持的有限度，一些复杂的业务计算转换还是需要手动编写代码。这个还是需要
         衡量自己应用的场景去制定数据转换方式实现 
         
         
##### 实践过程难点
      1.如何划分流处理框架下的根据描述节点生成对应的算子节点，这个实现就可以很好的将数据处理流程图----翻译为-->可执行程序
        （如何能覆盖80%的场景）,难以确定的点在于我不确定所实现的方式能否覆盖大部分场景!!
        
        我们需要深入理解数据处理流程，主要就是数据的变换，然后就是数据的查询、聚合查询和入库
      
                      
        
        
        
            
          
           
           
          
          
        
        
        
        
                